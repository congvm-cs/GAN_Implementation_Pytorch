{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "GAN_Implementation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmXbPlQInO8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prerequisites\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torchsummary import torchsummary\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie_-ti1InQ87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cabf0a4e-ad7b-411d-be05-2a4ba589d83a"
      },
      "source": [
        "print('Using \\'{}\\' in this session'.format(device))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 'cuda' in this session\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GgSGF9C0nO9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 100\n",
        "\n",
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()])\n",
        "#     transforms.Normalize(mean=0.5, \n",
        "#                          std=0.5)])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax6syl6ZnO9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "        \n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY2dg6nhnO9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fa81c978-ca0c-4c8f-c69d-2dfadafcf820"
      },
      "source": [
        "z_dim = 100\n",
        "mnist_dim = train_dataset.train_data.size(1)*train_dataset.train_data.size(2)\n",
        "\n",
        "\n",
        "G = Generator(g_input_dim=z_dim, g_output_dim=mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n44vMdcRnO9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "caf676a5-5f04-494c-f855-d18833191a2f"
      },
      "source": [
        "torchsummary.summary(G, (1, z_dim))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 256]          25,856\n",
            "            Linear-2               [-1, 1, 512]         131,584\n",
            "            Linear-3              [-1, 1, 1024]         525,312\n",
            "            Linear-4               [-1, 1, 784]         803,600\n",
            "================================================================\n",
            "Total params: 1,486,352\n",
            "Trainable params: 1,486,352\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 5.67\n",
            "Estimated Total Size (MB): 5.69\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDpxXJcznO9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "582610e8-8f21-4e4c-d234-3b3e5222b71e"
      },
      "source": [
        "D"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikubrn0JnO9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# optimizer\n",
        "lr = 0.0005\n",
        "G_optimizer = optim.Adam(G.parameters(), lr=0.0001)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr=0.00005)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U64ua_p5nO9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def D_train(x):\n",
        "    #------------------------------------\n",
        "    # Train the Discriminator\n",
        "    #------------------------------------\n",
        "    D.zero_grad()\n",
        "    \n",
        "    # Train on real image\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "    \n",
        "    \n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "    \n",
        "    # Train on fake image\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "    \n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "    \n",
        "    # BackProb & Optimize only D paramters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "    \n",
        "    return D_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvh31WpsnO92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def G_train(x):\n",
        "    #------------------------------------\n",
        "    # Train the Generator\n",
        "    #------------------------------------\n",
        "    \n",
        "    G.zero_grad()\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "    \n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "    \n",
        "    # backprob & optimize only G parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "    \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "03V6A1--nO98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "ef685702-b631-4442-8515-1d2f1681368f"
      },
      "source": [
        "n_epochs = 200\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "        \n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "        (epoch), n_epochs, \n",
        "        torch.mean(torch.FloatTensor(D_losses)), \n",
        "        torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200]: loss_d: 1.286, loss_g: 0.983\n",
            "[2/200]: loss_d: 1.341, loss_g: 0.837\n",
            "[3/200]: loss_d: 1.392, loss_g: 0.786\n",
            "[4/200]: loss_d: 1.400, loss_g: 0.769\n",
            "[5/200]: loss_d: 1.381, loss_g: 0.727\n",
            "[6/200]: loss_d: 1.413, loss_g: 0.726\n",
            "[7/200]: loss_d: 1.407, loss_g: 0.714\n",
            "[8/200]: loss_d: 1.405, loss_g: 0.711\n",
            "[9/200]: loss_d: 1.399, loss_g: 0.697\n",
            "[10/200]: loss_d: 1.401, loss_g: 0.699\n",
            "[11/200]: loss_d: 1.394, loss_g: 0.703\n",
            "[12/200]: loss_d: 1.398, loss_g: 0.707\n",
            "[13/200]: loss_d: 1.395, loss_g: 0.696\n",
            "[14/200]: loss_d: 1.397, loss_g: 0.702\n",
            "[15/200]: loss_d: 1.398, loss_g: 0.695\n",
            "[16/200]: loss_d: 1.390, loss_g: 0.699\n",
            "[17/200]: loss_d: 1.398, loss_g: 0.696\n",
            "[18/200]: loss_d: 1.391, loss_g: 0.696\n",
            "[19/200]: loss_d: 1.393, loss_g: 0.697\n",
            "[20/200]: loss_d: 1.394, loss_g: 0.697\n",
            "[21/200]: loss_d: 1.392, loss_g: 0.702\n",
            "[22/200]: loss_d: 1.392, loss_g: 0.695\n",
            "[23/200]: loss_d: 1.392, loss_g: 0.698\n",
            "[24/200]: loss_d: 1.391, loss_g: 0.700\n",
            "[25/200]: loss_d: 1.392, loss_g: 0.695\n",
            "[26/200]: loss_d: 1.396, loss_g: 0.696\n",
            "[27/200]: loss_d: 1.391, loss_g: 0.700\n",
            "[28/200]: loss_d: 1.391, loss_g: 0.694\n",
            "[29/200]: loss_d: 1.390, loss_g: 0.696\n",
            "[30/200]: loss_d: 1.391, loss_g: 0.699\n",
            "[31/200]: loss_d: 1.386, loss_g: 0.708\n",
            "[32/200]: loss_d: 1.394, loss_g: 0.694\n",
            "[33/200]: loss_d: 1.392, loss_g: 0.695\n",
            "[34/200]: loss_d: 1.390, loss_g: 0.698\n",
            "[35/200]: loss_d: 1.393, loss_g: 0.694\n",
            "[36/200]: loss_d: 1.392, loss_g: 0.695\n",
            "[37/200]: loss_d: 1.389, loss_g: 0.694\n",
            "[38/200]: loss_d: 1.394, loss_g: 0.696\n",
            "[39/200]: loss_d: 1.391, loss_g: 0.694\n",
            "[40/200]: loss_d: 1.386, loss_g: 0.696\n",
            "[41/200]: loss_d: 1.368, loss_g: 0.797\n",
            "[42/200]: loss_d: 1.396, loss_g: 0.702\n",
            "[43/200]: loss_d: 1.391, loss_g: 0.704\n",
            "[44/200]: loss_d: 1.390, loss_g: 0.696\n",
            "[45/200]: loss_d: 1.392, loss_g: 0.701\n",
            "[46/200]: loss_d: 1.394, loss_g: 0.706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nJjztk8nO-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    generated = G(test_z)\n",
        "\n",
        "    save_image(generated.view(generated.size(0), 1, 28, 28), './samples/sample_' + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-zKhmSOpLnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}